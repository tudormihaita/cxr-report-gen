tokenizer:
  source: "huggingface"
  pretrained_model_name_or_path: "emilyalsentzer/Bio_ClinicalBERT"
  cache_dir: "huggingface/tokenizers"

transform:
  inference:
    Resize:
      size: 224
    CenterCrop:
      size: 224

encoder:
  model:
#    fine-tuned inference
    name: "finetune_classifier"
    load_backbone_weights: "assets/checkpoints/clip-xrad-backbone.pt"
    freeze_backbone_weights: true

    image_encoder:
      source: "huggingface"
      name: 'microsoft/swin-tiny-patch4-window7-224'
      pretrained: true
      model_type: 'swin'

    classifier:
      config:
        name: "mlp"
        hidden_dim: 384
        n_class: 14

#    zero-shot inference
#    name: "pretrain_encoder"
#    temperature: 0.07
#
#    image_encoder:
#      source: "huggingface"
#      name: 'microsoft/swin-tiny-patch4-window7-224'
#      pretrained: true
#      model_type: 'swin'
#
#    text_encoder:
#      source: "huggingface"
#      name: emilyalsentzer/Bio_ClinicalBERT
#      pretrained: true
#      gradient_checkpointing: false
#      pooling: "eos" # one of { "eos" | "bos" | "mean" }
#      cache_dir: "huggingface/"
#      trust_remote_code: true
#      mlm_head: true
#
#    projection_head: # optional
#      name: "linear" # one of { "linear" | "mlp" }
#      dropout: 0.1
#      proj_dim: 512
  loss:
    classification:
    loss_ratio: 1.0

    contrastive_semantic:
      semantic_temperature: 1.0
      semantic_weight: 0.7
      loss_ratio: 1.0

decoder:
  model:
    name: "downstream_decoder"
    load_backbone_weights: "assets/checkpoints/clip-xrad-classifier.tar"
    freeze_backbone_weights: true

    image_encoder:
      source: "huggingface"
      name: 'microsoft/swin-tiny-patch4-window7-224'
      pretrained: true
      model_type: 'swin'
      hidden_size: 768

    text_decoder:
      source: "huggingface"
      name: "emilyalsentzer/Bio_ClinicalBERT"
      pretrained: true
      cache_dir: "huggingface/"
      trust_remote_code: true

      max_length: 256
      min_length: 128
      max_prompt_length: 77
      beam_size: 5

    prompt_constructor:
      prompt_strategy: "supervised"
      prompt_file_path: "assets/train_prompts_all.json"
      use_diverse_templates: false

      optimal_thresholds:
        "Atelectasis": 0.160
        "Cardiomegaly": 0.163
        "Consolidation": 0.071
        "Edema": 0.171
        "Enlarged Cardiomediastinum": 0.035
        "Fracture": 0.027
        "Lung Lesion": 0.080
        "Lung Opacity": 0.305
        "No Finding": 0.236
        "Pleural Effusion": 0.321
        "Pleural Other": 0.014
        "Pneumonia": 0.155
        "Pneumothorax": 0.072
        "Support Devices": 0.245

  loss:
    language_modeling:
      ignore_index: -100
      loss_ratio: 1.0